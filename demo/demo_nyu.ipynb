{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "code_root='/home/nileshk/Research3/3dRelnet/relative3d'\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import scipy.misc\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(osp.join(code_root, '..'))\n",
    "import pdb\n",
    "from absl import flags\n",
    "from relative3d.demo import demo_utils\n",
    "import cPickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flags.FLAGS(['demo'])\n",
    "opts =  flags.FLAGS\n",
    "opts.batch_size = 1\n",
    "opts.num_train_epoch = 8\n",
    "opts.name = 'rebt_nyu_dwr_mask_common_spatial_pos_ft'\n",
    "opts.classify_rot = True\n",
    "opts.classify_dir = True\n",
    "opts.pred_voxels = False\n",
    "opts.use_context = True\n",
    "# opts.pred_label = False\n",
    "opts.upsample_mask=True\n",
    "opts.pred_relative=True\n",
    "opts.use_mask_in_common=True\n",
    "opts.use_spatial_map=True\n",
    "opts.pred_labels=False\n",
    "opts.pretrained_shape_decoder=True\n",
    "opts.do_updates=True\n",
    "opts.dwr_model=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opts.classify_rot:\n",
    "    opts.nz_rot = 24\n",
    "else:\n",
    "    opts.nz_rot = 4\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = '../cachedir/snapshots/{}/pred_net_{}.pth'.format(opts.name, opts.num_train_epoch)\n",
    "pretrained_dict = torch.load(checkpoint)\n",
    "\n",
    "\n",
    "# renderer = demo_utils.DemoRenderer(opts)\n",
    "## Load input data\n",
    "\n",
    "\n",
    "\n",
    "def clean_checkpoint_file(ckpt_file):\n",
    "    checkpoint = torch.load(ckpt_file)\n",
    "    keys = checkpoint.keys()\n",
    "    \n",
    "    temp = [key for key in keys if 'relative_quat_predictor' in key ] +  [key for key in keys if 'relative_encoder.encoder_joint_scale' in key]\n",
    "    if len(temp) > 0:\n",
    "        for t in temp:\n",
    "            checkpoint.pop(t)\n",
    "\n",
    "#         with open(ckpt_file, 'w') as f:\n",
    "#             pkl.dump(f, checkpoint)\n",
    "        torch.save(checkpoint, ckpt_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_file = '../cachedir/snapshots/{}/pred_net_{}.pth'.format(opts.name, opts.num_train_epoch)\n",
    "clean_checkpoint_file(ckpt_file)\n",
    "tester = demo_utils.DemoTester(opts)\n",
    "tester.init_testing()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'nyu'\n",
    "\n",
    "img = scipy.misc.imread('./data/{}_img.png'.format(dataset))\n",
    "\n",
    "img_fine = scipy.misc.imresize(img, (opts.img_height_fine, opts.img_width_fine))\n",
    "img_fine = np.transpose(img_fine, (2,0,1))\n",
    "\n",
    "img_coarse = scipy.misc.imresize(img, (opts.img_height, opts.img_width))\n",
    "img_coarse = np.transpose(img_coarse, (2,0,1))\n",
    "\n",
    "\n",
    "# proposals = sio.loadmat('./data/{}_proposals.mat'.format(dataset))['proposals'][:, 0:4]\n",
    "proposals_data = sio.loadmat('./data/{}_proposals.mat'.format(dataset))\n",
    "scores = proposals_data['score']\n",
    "proposals = proposals_data['boxes'][:,0:4]\n",
    "inputs = {}\n",
    "inputs['img'] = torch.from_numpy(img_coarse/255.0).unsqueeze(0)\n",
    "inputs['img_fine'] = torch.from_numpy(img_fine/255.0).unsqueeze(0)\n",
    "inputs['bboxes'] = [torch.from_numpy(proposals)]\n",
    "inputs['scores'] = [torch.from_numpy(scores)]\n",
    "inputs['empty'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.set_input(inputs)\n",
    "objects = tester.predict_box3d()\n",
    "visuals = tester.render_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 2, figsize=(20, 8))\n",
    "\n",
    "\n",
    "\n",
    "axarr[0, 0].imshow(visuals['img'])\n",
    "axarr[0, 0].axis('off')\n",
    "axarr[0, 1].imshow(visuals['b_pred_objects_cam_view'])\n",
    "axarr[0, 1].axis('off')\n",
    "axarr[1, 0].imshow(visuals['img_roi'])\n",
    "axarr[1, 0].axis('off')\n",
    "axarr[1, 1].imshow(visuals['b_pred_scene_cam_view'])\n",
    "axarr[1, 1].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3drelnet",
   "language": "python",
   "name": "3drelnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
